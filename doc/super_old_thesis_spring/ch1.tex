\documentclass{elsart1p}

\usepackage{amssymb}
\usepackage{multirow}
\usepackage{graphicx}

\begin{document}

\begin{frontmatter}

\title{Reservoir Computing and Dynamical Systems Theory}

\author{Ralph J. Bean III}

\end{frontmatter}

\section{Introduction}

The neural network method is one method among many that has generated
excitement for those interested in the tasks of time series
classification, prediction, and control.
At the most general level, neural networks are pattern machines,
machines whose output functions are patterns that are hopefully in some
useful or interesting relationship with its set of pattern inputs
\cite{weigend}.
With an eye towards time series-related tasks, neural networks have
undergone a series of important developments in recent years.
First, a reemphasis on the coding of information in spikes at the
individual level of the neuron has resulted, on the one hand, with neural
networks that are much more theoretically powerful, and on the other, with
neural networks that are much more computationally expensive to simulate 
\cite{maass_book}.  Second, the simultaneous independent breakthrough in 2002 by
Jaeger and Maass showed a way around the long-standing limitations
of the training recurrent neural networks, or networks that feedback on
themselves \cite{maass_original, jaeger_original, doya}.

For those interested in machine learning on time-series data, both of
these developments are important because both of them integrate the
temporal component of their inputs into their inherent dynamics.

The purpose of this document is to lay the groundwork for my M.S. thesis.
Building on the survey of material researched and presented in this paper,
I there intend to analytically derive constraints on the parameters of a
recurrent network of spiking neurons such that its maximal lyapunov exponent 
$h_{k}$ is greater than, but almost equal to, $0$.

%\section{Neural Computing}

%\textbf{Drop Maass hard}.

\section{Reservoir Computing}
In 2002, Jaeger and Maass independently published results on supervised
learning architectures for recurrent neural networks, analog in the former
and digital in the latter \cite{jaeger_original, maass_original}.  For an
up to date review of the two with comparisons and benchmarks see \cite{verstraeten}.

The training of recurrent neural networks is fundamentally problematic given
the central paradigm for learning algorithms that do not entail feedback.
Variants of gradient descent or hill climbing algorithms used to search the parameter
space for an optimal configuration rely on that parameter space being smooth
under evaluation.  The introduction of recurrent feedback loops to neural networks comes with the problem of bifurcations.  Here, learning rules may be inching towards what appears a good solution only to fall off a bifurcation point into
a system with drastically different behavior \cite{doya}.

Jaeger and Maass' techniques both consist of building a randomly constructed,
non-learning, and recurrent reservoir of neurons whose output is 
connected to a linear readout \cite{maass_metaphor}.

%\textbf{TODO - diagram of the reservoir-readout model}

The performance of these systems can vary wildly.  The random construction of
the reservoir leaves it prone to doing any number of unproductive things
to its input.  Fortunately, some metrics over the dynamical behavior of
reservoirs have been proposed.  Systems for which these metrics are optimized
result in sharp performance increases at task-learning for the linear readout.

One such metric is the average degree of linear 
indepenence among reservoir
states over time.  Intuitively, optimizing this makes sense.  
A linear classification
readout would have more degrees of freedom with which to work if the
state vectors at all the sampled timesteps filled out their vector space
\cite{maass_what_makes}.

%While there are positive experimental results published for this metric,
%      there is a theoretical problem.  One can construct a toy system which
%      maximizes linear independence among its iterates but yet its iterates
%      contain no information about the input.  
%      \textbf{TODO} -- describe that toy system in detail (not in the 
%                       survey section).

Another such metric is the maximal lyapunov exponent of the system.  
Maass' prescription
is to randomly search for reservoirs that have a maximal lyapunov exponent
greater than, but nearly 0.  This gives systems whose inputs' trajectories
exponentially diverge, but by as small an exponent as possible.  The 
experimentally determined high performance of these systems is what has
triggered excitement around computing 'at the edge of chaos' \cite{verstraeten}.

More qualitatively, Maass' work describes two antagonistic properties of 
computationally powerful reservoirs.  They must have both the \textit{
    Separation Property} and \textit{Fading Memory}.

    A state vector of a system with fading memory contains in it some
    information about past inputs up through some maximum time window.
    Alternatively, a system with fading memory has the property that 
    two different trajectories which may be far apart will converge to
    the same orbit if they begin receiving identical input.

    The separation property, on the other hand, entails that two different
    online signals evolve as different and separate trajectories through
    the state space.

    Chaotic systems clearly have the separation property, but they have poor
    fading memory.  Highly ordered systems have the fading memory property, 
    but separate their inputs only weakly if at all \cite{maass_what_makes}.

    The above observations coupled with the accumulating positive 
    experimental results make further investigation of these new 
    techniques an interesting avenue.


\section{Dynamical Systems}
The route by which the above will be investigated is by way of dynamical systems theory.
Dynamical systems theory is the branch of mathematics that is 
concerned with systems of change equations and how the families of
solutions to these equations evolve over time.
In some cases, i.e. for linear
autonomous systems, explicit solutions can be found in terms of an
independant time variable $t$ which guarantees knowledge of the state at
any time along the evolution of the solution.  For \textit{most} equations, and
in particular the ones we are interested in here, this cannot be done.
The situation is not without hope, however, because the tools developed 
in the study of linear autonomous systems can be used in the nonlinear 
case with some modification and in tandem with specifically nonlinear 
techniques.


\subsection{Linear techniques}
A linear equation on one variable is an equation of the form
$f : \mathbb{R} \rightarrow \mathbb{R}$
$$f(x) = ax$$ where $a$ is a parameter.
The equation is called
\textit{linear} because there are no squared or higher terms on the variable
$x$.  Every straight line which passes through the origin is described by the above equation for a particular value of $a$.

Linear equations of higher dimension are of the form 
$f : \mathbb{R}^{n} \rightarrow \mathbb{R}^{n}$
$$f(\vec{x}) = A \cdot \vec{x}$$
Where $\vec{x} \in \mathbb{R}^{n}, A \in \mathbb{M}_{n,n}$.  Each 
component of $f(\vec{x})$ can be expressed as a linear combination of the 
rows of $A$ and the terms of $\vec{x}$.

The relationship of $f(\vec{x})$ to the change rule determines which of two
types a system is.

\textit{Continuous} dynamical systems are given by
a system of differential equations.
$$\vec{x}^{\prime} = f(\vec{x})$$
\textit{Discrete} dynamical systems are given by a map
$$\vec{x}_{n+1} = f(\vec{x}_{n})$$

We are concerned with both but will restrict ourselves to the continuous case
for now.

If the system at hand is linear, there are a number of well-developed tools
from linear algebra that can help us understand the behavior over time.
Setting $\vec{x}^{\prime} = \vec{0}$, we can solve for the roots of 
$f(\vec{x})$ which correspond to equilibria of the system.  While 
equilibria solutions are fixed, the qualitative behavior of solutions passing
near the equilibria can be determined by eigenvalue analysis of $A$.
The product of a matrix $A$ with any vector can be expressed as a linear combination of the eigenvalues and eigenvectors of that matrix.  Since our 
derivative $\vec{x}^{\prime}$ is defined everywhere by such a matrix product,
we can characterize the behavior of solutions everywhere by such linear combinations.

\begin{figure}[htp]
\centering
\includegraphics[width=400pt]{figures/eigenvalues.pdf}
\caption{Phase portraits of autonomous, linear, planar systems with 
    sundry eigenvalues.  Phase portraits attempt to portray a subset
of the infinite solution curves through the phase space to give the
qualitatively 'gist' of the system.
The top left panel depicts a \textit{sink} with two negative eigenvalues.
Top right:  a \textit{source} with two positive eigenvalues.  
Bottom left:  a \textit{saddle} with one positive and one negative eigenvalue.
Bottom right: a \textit{spiral source} with a complex conjugate pair of 
eigenvalues with positive real part.}
\label{fig:eigenvalues}
\end{figure}

Consider the evolution of $\vec{x}^{\prime} = A\cdot\vec{x}$ for a matrix $A$ 
with eigenvalues with only positive real part.  For any $\vec{x}$, the change 
in $\vec{x}$ with respect to $t$ will be positive everywhere
and the flow of $\vec{x}$ will tend to $\infty$.  For a matrix $A$ with 
only negative real part eigenvalues, the derivative of $\vec{x}$ will 
be negative everywhere and $\vec{x}$ will necessarily 
tend to the origin.  Matrices $A$ with complex conjugate eigenvalues exhibit 
subclasses of spiral behavior dependent on the sign of both the real 
and imaginary parts.

As depicted in figure 1,
equilibria with positive eigenvalues are called \textit{sources} 
or \textit{unstable} nodes since solutions tend away except for 
    the solution on equilibria point itself.  Those with negative 
    are called \textit{sinks} or \textit{stable} nodes.  In the 2D 
    planar case, equilibria with mixed (one positive, one negative) 
    are called \textit{saddle} due to the shape of their vector fields.  
    But for
the purpose of generalizing these ideas to the unimaginable higher dimensions,
it is worth pointing out that a saddle is more accurately described
as an equilibrium with one stable, one-dimensional subspace and another 
unstable, one-dimensional subspace.  Beyond eigenvalue analysis, other
linear algebra techinques apply such as orthogonal decomposition and,
LU-factorization.

\subsubsection{Relevant Spaces and Bifurcation}
The state space or phase space (the terms will be used interchangeably), 
denoted $\mathbb{S}$, of a dynamical system is a space in which 
every point is a unique \textit{state}, $\vec{s}$, of the system.  For every
$\vec{s} \in \mathbb{S}$, an either discrete or continuous change rule describes
uniquely the evolution of that point both forwards and backwards for all time.

Strictly speaking, a dynamical system is defined completely by its 
change rule and its state space $(f, \mathbb{S})$ \cite{hirsch}.  

There are a number of different ways of conceptualizing this all with varying
degrees of usefulness.  For instance, for a set $X$ and a \textit{topology} 
$T$ composed of
open subsets of $X$, the pair $(X,T)$ defines a \textit{topological space}.

For a system, one typical task of dynamical analysis is to determine its
$\alpha$ and $\omega$-sets (to be discussed more later).  Discussion of the
system can then proceed not in terms of its change rule but in terms of the topological properties of its 
$\alpha$ and $\omega$-sets as open subsets of its set of possible states 
\cite{basener}.


Another, and perhaps more familiar, conceptualization is the 
characterization of
a system's \textit{tangent space}.  For a system on $\mathbb{R^{n}}$, remember
that at every $n$-dimensional state vector there exists another $n$-dimensional
vector under $f$ that describes the change at that location.  Then,
Together, these change vectors compose the tangent space of the phase space.
The easiest case to imagine is for a one-dimensional dynamical system, then
the orthogonal composition of the $x^{\prime}$ tangent space and the
$x$ phase space completely describe the system.  Not much has changed from
our original definition, except for the introduction of a new 
geometric lens with which to consider a system's dynamics \cite{arrowsmith}.

Consider the effect that a given change rule has on the phase space.  Every
point is mapped uniquely to a flow.  How does this
set of flows, this structuring of the phase space itself change for change
rules that are 'close' to one another?  Introducing parameters to the change
rule gives us a vehicle to explore the question.

The \textit{parameter space}, $\mathbb{P}$ of a dynamical system is a space in
which every point corresponds to a unique combination of parameters for a
particular system and therefore to a unique structuring of the phase space.

For example, take the nonlinear, one-dimensional system 
$$x^{\prime} = f_{h}(x) = x(1-x)-h.$$  Here, $h$
is the only parameter so $\mathbb{P} \equiv \mathbb{R}$.  Solving for the
equilibria $x^{\prime} = 0$ in terms of $h$ gives $$x^{*}=\frac{1}{2} \pm \sqrt{\frac{1}{4} - h}.$$
What are the equilibria $x^{*}$ for different $h$?  At $h=0$ there are two equilibria $x^{*}=\{0,1\}$.  At $h=\frac{1}{4}$ there is only one equilibria at $x^{*}=\frac{1}{2}$.  For 
$h > \frac{1}{4}$ the term inside the square root is negative, and so we have complex conjugate roots for the system.  A few select phase portraits are depicted in figure 2.  If we were here able to animate the flows of $f_{h}$ while slowly increasing $h$, we would see the two equilibria move towards one another, merge at $h=\frac{1}{4}$ into a stable fixed point and subsequently vanish altogether.

% TODO include bifurcation diagram for completeness.

\begin{figure}[htp]
\centering
\includegraphics[width=400pt]{figures/bifurcation1.pdf}
\caption{The one dimensional system $x\prime = f_{h}(x) = x(1-x)-h$.
Top left $h=0$.  Top right $h=\frac{1}{8}$.
Bottom left, bifurcation at $h=\frac{1}{4}$.
Bottom right $h=\frac{3}{8}$.} 
\label{fig:bifurc}
\end{figure}


$h=\frac{1}{4}$ is called a \textit{bifurcation point}, a shape (in this case, a point) in parameter space, the points on either side of which correspond to qualitatively different dynamics in the related system.

There are a number of studied and named bifurcations that occur in families of systems, namely the heteroclinic, homoclinic, period doubling, pitchfork, saddle-node, tangent, and Hopf bifurcations.  Period doubling bifurcations, one signature of chaos in discrete systems as well as the continuous-system Hopf bifurcation, exhibited by the FitzHugh-Nagumo neural model, are of interest to us but 
first require an introduction to techniques for nonlinear dynamical systems.

%\subsubsection{it is worth mentioning: poincare map}
%\textbf{TODO}
%I need to write here about Poincar\'{e} maps for discretizing 
%continuous neural equations.  Its a simple idea with lots of theorems as
%a result 

\subsection{ Local Nonlinear Techniques }
The introduction of non-linearity creates problems.  No longer can we
generalize behavior about solutions away from equilibria by analyzing the
eigenvalues of the equilibria alone.  Furthermore, we cannot even
represent $f(\vec{x})$ as a matrix product; directly solving for
the eigenvalues is not even an option.

The first technique to apply is to
linearize the nonlinear system about a particular equilibrium and analyze
the properties of that system.  This can tell us at least something about
the system, but any results obtained apply only locally to an 
arbitrarilly small neighborhood about that point.
The method of linearization on non-linear systems is justified by 
the observation
that any non-linear terms, when within the unit-sphere, become less and
less influential the closer they are evaluated to the origin and thus, the
linearization becomes more and more valid.

The Jacobian matrix gives the linearization of a system $f_{\vec{x}}$ where:

\[ J_{f} = \left( \begin{array}{cccc}

\frac{\partial f_{1}}{\partial x_{1}} & 
\frac{\partial f_{1}}{\partial x_{2}} & 
\cdots &
\frac{\partial f_{1}}{\partial x_{n}} \\

\frac{\partial f_{2}}{\partial x_{1}} & 
\frac{\partial f_{2}}{\partial x_{2}} & 
 &
\frac{\partial f_{2}}{\partial x_{n}} \\

\vdots & & \ddots & \vdots \\


\frac{\partial f_{n}}{\partial x_{1}} & 
\frac{\partial f_{n}}{\partial x_{2}} & 
\cdots &
\frac{\partial f_{n}}{\partial x_{n}} \end{array} \right)\] 

Solving for the eigenvalues of the Jacobian evaluated at the equilibria gives
information about their \textit{local} stability.  This technique,
however, gives us valid information only if the linearization is nonhyperbolic,
    which is to say, it has no zero-real-part eigenvalues.  When the
    linearization is hyperbolic, global nonlinearities ultimately determine
    the fate of orbits as arbitrarily close to the hyperbolic equilibria as you
    would like.

The Jacobian will come into play again later when calculating the Lyapunov
exponents of discrete systems.

\subsubsection{ Hopf Bifurcations }
The famous Hopf Bifurcation is an example of the emergence of a globally
stable limit cycle (figure 2): an attractor which is periodic and not one of the
roots of $f(\vec{x})$ as all attractors have been so far.  This occurs when
there is a locally stable fixed point equilibria dominated by linear terms 
but withnon-linear stability towards that fixed point as well.  
Parameterization of the system such that the linearization goes 
hyperbolic results in antagonism
between local and global, linear and nonlinear terms which 
stabilize at a not-necessarilly circular but nonetheless closed limit cycle 
about the fixed point \cite{arrowsmith, hirsch}.

\begin{figure}[htp]
\centering
\includegraphics[width=200pt]{figures/hopf.pdf}
\caption{A system having undergone a Hopf bifurcation with an unstable node
and a stable periodic orbit.} 
\label{fig:hopf}
\end{figure}


The FitzHugh-Nagumo model of the neuron was one of the first proposed
alongside a discussion of dynamical systems theory.  Supercritical orbits in those systems model 
subthreshold oscillations and tonic spiking of neurons and the presence of
post Hopf bifurcation orbits correspond to tonic spiking patterns \cite{fitzhugh, izhikevich_book}.

\begin{figure}[htp]
\centering
\includegraphics[width=400pt]{figures/fitzhugh_bifurcation1.pdf}
\caption{Phase portraits of the FitzHugh-Nagumo model of the neuron for different values of the stimulus parameter $I$. 
The FitzHugh-Nagumo model undergoes a Hopf Bifurcation that
models cell depolarization.  The horizontal v-axis models the
internal voltage and the vertical u-axis models the recovery variable.
The top left panel depicts the phase
portrait of the model when a constant hyperpolarizing (inhibitory) stimulus is applied.  As the inhibitory stimulus modeled by the parameter $I$ decreases
one can see the amplification of subthreshold oscillations in the top right
panel.  $I$ is lowered further in the bottom left panel pushing the system past
a bifurcation point in both that and the bottom right panel.}
\label{fig:fhn1}
\end{figure}

\subsection{ Global Nonlinear Techniques }
The Hopf Bifurcation above is a global phenomena that can be assessed with
local analysis but there exist global techniques that do not depend on
linearization at equilibria and that can aid in determining systems' behavior.

For a system of the form $f : \mathbb{R} \rightarrow \mathbb{R}$
\[\begin{array}{ccc}
x_{1}^{\prime} & = & f_{1}(x_{1}, \cdots, x_{n}) \\
& \vdots & \\
x_{n}^{\prime} & = & f_{n}(x_{1}, \cdots, x_{n}), \end{array} \] 

The $x_{j}$-nullcline is the $n-1$ dimensional curve that traces 
where $x_{j}^{\prime} = 0$.  Each of the $x_{j}$-nullclines 
typically carve $\mathbb{R}^{n}$ up into halves
and allow us to then decompose the phase space into a collection of open sets.
Inside each of these sets, we know that the direction field is always pointing
in one particular quadrant and can then develop constructions about the behavior
of orbits.  You can, for instance rule out travel from one set to another, 
pruning a graph of possible set transitions \cite{hirsch}.  Furthermore, 
the collection of open sets given by nullcline decomposition is, by definition,
a topology.  This allows for exportation of the system to other mathematical
domains for analysis \cite{basener, arrowsmith}.
%
% I think I just included this as filler beforehand.  It is not necessary
%  now.
%
%Other global nonlinear techniques include identifying the system as
%being of a particular form about which there are particularly helpful theorems.

%Gradient systems are of the form
%$$\vec{x}^{\prime} = -\nabla V(\vec{x})$$
%For some $V : \mathbb{R}^{n} \rightarrow \mathbb{R}$ where $\nabla V = \left( \frac{\partial V}{\partial x_{1}},\cdots,\frac{\partial V}{\partial x_{n}}  \right)$.  

%Planar Hamiltonian systems are of the form
%$$x^{\prime} = \frac{\partial H}{\partial y}(x,y)$$
%$$y^{\prime} = -\frac{\partial H}{\partial x}(x,y)$$
%for some function $H : \mathbb{R}^{n} \rightarrow \mathbb{R}$.  Hamiltonian systems enjoy the property that the derivative of the hamiltonian function is 
%zero everywhere, so every level curve of the surface defined by $H(x,y)$ is
%a solution of the system.  The equation can be solved explicitly without much
%if any work.  This becomes more complicated in cases with dimension greater
%than 2 but is still relevant.

\subsection{Chaos in Nonlinear Systems}
A function $f : I \rightarrow I$ where $I \subset \mathbb{S}$ is said to be chaotic \cite{hirsch} iff:
\begin{enumerate}
\item Periodic points of $f$ are dense in $I$;
\item $f$ is transitive on $I$;  that is, given any two subintervals $U_{1}$
and $U_{2}$ in $I$, there is a point $x_{0} \in U_{1}$ and an $n > 0$ such 
that $f^{n}(x_{0}) \in U_{2}$;
\item $f$ has sensitive dependence in $i$; that is, there is a
\textit{sensitivity constant} $\beta$ such that, for any $x_{0} \in I$ and
any open interval $U$ about $x_{0}$, there is some seed $y_{0} \in U$ and 
$n > 0$ such that
$$|f^{n}(x_{0}) - f^{n}(y_{0})| > \beta$$
\end{enumerate}

The set of periodic points of $f$ being dense in $I$ amounts to saying that
there are many such periodic points.  More formally, there exist points in $I$
that are surrounded by periodic points of $f$ with arbitrary closeness.

For the reader unfamiliar with the notion of set density, consider
this example of a set of numbers that is dense in another set of numbers.
The set of rational numbers $\mathbb{Q}$ is dense in the set of real numbers 
$\mathbb{R}$.  Given any $x \in \mathbb{R}$, one can find (more 
appropriately, construct) a number $y \in \mathbb{Q}$ that is 
\textit{arbitrarilly} close to $x$.  For instance, say I have chosen an $x$
and you pick such a $y$ as close to $x$ as you can.
For arguments sake, let's assume $y < x$.  Furthermore, we know that
the set of rational number $\mathbb{Q}$ is defined as the set of numbers
that can be constructed as fractions of integers.  Therefore, your 
$y$ must be equal to some fraction $\frac{z_{1}}{z_{2}}$ for some $z_{1}, z_{2} \in \mathbb{Z}$.  No matter
your choice, since there are an infinite number of integers 
I can always pick $w = \frac{z_{3}}{z_{4}}$ such that $w$ falls between $y$ and $z$.  Hopefully
this illustration of what it means for a set to be dense in another set
illuminates what it means for a system's set of periodic points to be
dense in a subregion of its state space.

The second condition, the transitivity of $f$, amounts to a \textit{mixing} 
requirement.  Points from $U_{1}$ at some time end up in $U_{2}$ and points 
from $U_{2}$ at some time end up in $U_{1}$.  This follows from the above 
property of the density of periodic points of $f$.

The third property, sensitive dependence on initial conditions, is the most
popularly understood aspect of chaos, is the more hotly contested and 
is alternatively known as 'the butterfly effect'.  
See \cite{history} for a thorough treatment of the
confluence of Lorenz and other non-mathematicians as well as broad cultural reinpretations of chaos theory.  In our subsequent investigation of neural systems,
it is this condition of chaos on which we will rely most heavily.  However,
computing an constant upper-bound for $\beta$ is a non-trivial task.

A reasonable alternative to this condition 
involves characterizing the \textit{rate} of
separation of orbits by calculating \textit{Lyapunov exponents}.
Define the $k$th Lyapunov exponent, $h_{k}$, as
$$h_{k} = \log \left( \lim \limits_{n \to \infty} (r_{k}^{n})^{\frac{1}{n}}\right)$$
Although the value of $h_{k}$ is that in which we are most interested (is the rate of separation exponential or not?), introducing the $k$th \textit{Lyapunov number} $L_{k}$ simplifies the equation and is given by
$$L_{k} = e^{h_{k}} = \lim \limits_{n \to \infty} (r_{k}^{n})^{\frac{1}{n}}$$
For a trajectory through the state space, consider the effect had on the points on a hypersphere of arbitrarilly small radius centered on the initial seed of 
the orbit.  Over the evolution of the system, this hypersphere evolves into
a hyperellipsoid.
The value of $r_{k}^{n}$ are the $k$th longest orthogonal axis of the hyperellipsoid at the $n$th iterative application of $f$ \cite{alligood, nikilov, verstraeten}.

Numerically approximating the Lyapunov exponents means iterating the system
into its future and measuring these axes.  This is just as computationally
intensive as calculating the original sensitivity constant given in \cite{hirsch}.  Furthermore, approximation in the presence of chaos
is problematic with regard to numeric precision.

However, a solution is shown in \cite{alligood}.
The radii of the hyperellipsoid, $r_{k}^{n}$, are given by the
square root of the eigenvalues of $J_{n}J_{n}^{T}$ where $J_{n}$ is the 
Jacobian of the $n$th iteration.  This can be solved explicitly and
while non-trivial, is much less computationally expensive.

This method is the cornerstone theorem on which results will be built in later
chapters.

\textit{Rough Draft Note} -- I stumbled on Gromwall's inequality during the
completion of this draft.  It may be useful here.

\subsubsection{Disagreements on Chaos}
As was suggested above, there is some disagreement within the 
mathematical community over what counts as chaos.  Of the three conditions
mentioned above, the first two (density of periodic orbits in $I$ and
transitivity of $f$ over $I$) are purely topological which is to say they
require no notion of
distance.  The third condition and consequently the Lyapunov method 
entail a notion of distance 
and so apply only to 'special' cases of dynamical systems where the 
state space is a metric space.
The disagreement
centers around the degree of purity in our definition of chaos.  However,
for the purpose here of understanding neuron dynamics in the computational
domain, measurement is a must.  

\subsubsection{Strange Attractors}

The $\omega$-set or \textit{limit set} of a dynamical system is the set 
of points in the state
space to which all trajectories converge as $t \rightarrow \infty$.  For a 
linear system with a single sink equilibrium $\vec{x}^{*}$, 
$\omega=\{\vec{x}^{*}\}$.  For a linear system with a single source equilibrium,
$\omega=\{\}$.  For a system with a stable limit cycle, $\omega$ includes
every point on that limit cycle plus any other stable fixed points elsewhere
in the state space.  For the trivial system $\vec{x}^{\prime}=\vec{0}, \omega=\mathbb{S}$, the entire phase space.

Conversely, we say the $\alpha$-set for a system is the set of points
in the state space to which all trajectories converge as 
$t \rightarrow -\infty$.  This set includes all unstable fixed points and
all points on unstable periodic orbits.

For chaos to be possible, there must exist a chaotic attractor or 
\textit{strange attractor} in
the state space, typically denoted $\Lambda$.  
From the transitivity condition of chaos in a region, 
points from every subregion must visit every other subregion in their
flow.  A strange attractor, by definition, is not so strange; it is the
$\omega$-set of the chaotic region, or, a subset of the periodic points of $f$
that are also stable.  Its strangeness comes from the requirement that it
must be dense in the region and therfore occupy every subregion of the region
and yet still be a subset of that region.  
Chaotic attractors on the real line typically resemble Cantor's middle-thirds
set or Cantor's dust.
The Smale Horseshoe map is
a symbolic dynamical system constructed for the purpose of demonstrating 
just such a set:  an $\omega$-set that is a vanishingly small subset of 
the chaotic region that is invariant and dense in that region.

As an aside towards computer scientists, the Smale Horseshoe map serves
a function for dynamical systems theory quite similar to the 
boolean satisfiability problem ($SAT$) in computing theory.  Formalized by
Stephen Cook, $SAT$ was the first
problem to be shown to be in the set NP-complete, which informally, means that
it is as hard as 'the hardest problem in the set NP' and is itself in the set
NP.  For a problem in question $Q$, showing $SAT \leq_{m}^{p} Q$, which is 
read as 'SAT is polynomial time many-to-one reducible to Q', 
and showing that $Q$ is also in NP is sufficiently 
rigorous proof that $Q$ is in NP-Complete.  

In practice, reduction of $SAT$ to $Q$ is shown by providing a function $f$ 
such that
$SAT(x) = f^{-1}(Q(f(x)))$ for all $x$ where $f$ runs in polynomial time.
Furthermore, this determination of upper-bounds is transitive so reduction 
to $Q$ from any $SAT$-reducible problem is also sufficient.\cite{complexity}

Stephen Smale's Horeshoe map $F_{Smale}$ was the first map to be shown to 
have a strange
attractor (actually disproving his own conjecture that no such $\omega$-sets 
        existed)
\cite{history}.  To show that a system $f : U \rightarrow U$ is chaotic
on $U$, 
it is sufficient
to show that $(f,U)$ has a chaotic attractor.  To show that it has a
chaotic attractor it is sufficient to show that it is topologically conjugate
to the Smale Horsehoe map.  

In practice, conjugacy is shown 
by providing a homeomorphism $h(x)$ such that $h(F_{Smale}(x)) = f(h(x))$.
The set of flows of $F_{Smale}$ is continuously mapped to the
corresponding set of flows of $f$ which must then share continuously
mapped $\alpha$ and $\omega$-sets.  Since $F_{Smale}$ has a strange
attractor, so too does $f$.

\textit(Rough Draft note:)  -- I do not anticipate results regarding
a strange attractor.  The much studied Lorenz system 
was only proven to have a strange attractor
in 2001 \cite{warwick}.


%\section{Spiking Neurons}
%\textbf{ TODO } - this entire section.  Cite Dayan and Abbot and Maass' books.
%General discussion
%  need more in the long run
%
%\textbf{TODO}
%Hodgkin-Huxley
%
%\textbf{TODO}
%Leaky Integrate and Fire
%
%\textbf{TODO}
%Izhikevich
%
%\textbf{TODO}
%FitzHugh-Naguma (!)
%\section{Fundamental Problems and Future Work}
%\textbf{TODO}
%finish this document (figures, in particular)
%
%\textbf{TODO}
%workable model (FitzHugh-Naguma) -- extend and introduce third dimension.
%
%\textbf{TODO}
%considering inputs
%
%\textbf{TODO}
%nullcline decomposition $\rightarrow$ poincare map $\rightarrow$ attractors?
%
%\textbf{TODO}
%jedge of chaos via lyapunov work

\bibliographystyle{plain}
\bibliography{sample}

\begin{thebibliography}{widest-label}
\bibitem{alligood}
 K. Alligood, T. Sauer, J.A. Yorke
 \emph{Chaos:  An Introduction to Dynamical Systems},
 Springer-Verlag, 
 1997.
\bibitem{arrowsmith}
 D. Arrowsmith and C.M. Place,
 \emph{An Introduction to Dynamical Systems},
 Cambridge University Press,
 1990.
\bibitem{doya}
 K. Doya,
 \emph{Bifurcations in the Learning of Recurrent Neural Networks},
 Proceedings of the 1992 IEEE International Symposium on Circuits and Systems,
 2777-2780,
 1992.
\bibitem{weigend}
 A. Weigend and N. Gershenfeld,
 \emph{Time Series Prediction.  Forecasting the Future and Understanding the Past},
 Addison-Wesley,
 1994.
\bibitem{history}
 D. Aubin and A. Dahan Dalmedico,
 \emph{Writing the History of Dynamical Systems and Chaos:  Longue Dur\'ee and Revolution, Disciplines, and Cultures},
 Historia Mathematica,
 vol. 29,
 pgs 273-339,
 2002.
\bibitem{complexity}
 S. Cook,
 \emph{The Complexity of Theorem Proving Procedures},
 Proceedings of the third annual ACM symposium on Theory of computing,
 1971.
\bibitem{basener}
 W. F. Basener,
 \emph{Topology and its Applications},
 Wiley-Interscience,
 2006.
\bibitem{dayan}
 P. Dayan and L. F. Abbott,
 \emph{Theoretical Neuroscience:  Computational and Mathematical Modeling of Neural Systems},
 The MIT Press,
 2001.
\bibitem{fitzhugh}
 C. Rocsoreanu, A. Georgescu, and N. Giurgiteanu,
 \emph{The Fitzhugh-nagumo model:  Bifurcations and Dynamics},
 Kluwer,
 2000.
\bibitem{hirsch}
 M. W. Hirsch, S. Smale, R. L. Devaney,
 \emph{Differential Equations, Dynamical System, and an Introduction to Chaos},
 Elsevier,
 2004.
\bibitem{izhikevich_book}
 E. Izhikevich,
 \emph{Dynamical Systems in Neuroscience:  The Geometry of Excitability and Bursting},
 The MIT Press,
 2007.
\bibitem{maass_what_makes}
 R. Legenstein and W. Maass,
 \emph{What makes a dynamical system computationally powerful?}
 Haykin, Principe, Sejnowski, and McWhirter:
 New Directions in Statistical Signal Processing:  From Systems to Brain
 2005.
\bibitem{maass_metaphor}
 T. Natschl\"ager, W. Maass, H. Markram,
 \emph{The "Liquid Computer":  A Novel Strategy for Real-Time Computing on Time Series}
  Special Issue on Foundations of Information Processing of TELEMATIK, 
  vol. 8, 
  num. 1, 
  p. 39-43,
  2002 
\bibitem{maass_book}
 W. Maass and C. M. Bishop,
 \emph{Pulsed Neural Networks},
 The MIT Press,
 1999.
\bibitem{maass_original}
 W. Maass, T. Natschl\"ager, and H. Markram,
 \emph{A Model for Real-Time Computation in Generic Neural Microcircuits},
 Proc. of NIPS 2002, 
 Advances in Neural Information Processing Systems, 
 volume 15, 
 pages 229-236. 
 MIT Press, 
 2003.
\bibitem{nikilov}
 S. Nikolov, and B. Bozhkov,
 \emph{Bifurcations and chaotic behavior on the Lanford system},
 Chaos, Solitons and Fractals
 vol. 21,
 pgs 803-808,
 2004.
\bibitem{jaeger_original}
  H. Jaeger,
  \emph{The "echo state" approach to analysing and training recurrent neural networks}. 
  GMD Report 148, 
  GMD - German National Research Institute for Computer Science,
  2001.
\bibitem{verstraeten}
 D. Verstraeten, B. Scharuwen, M. D'Haene, D. Stroobandt,
 \emph{An experimental unification of reservoir computing methods},
 Neural Networks,
 vol. 20,
 pgs 391-403,
 2007.
\bibitem{warwick}
 W. Tucker,
 \emph{The Lorenz attractor exists}.
 C. R. Acad. Sci. Ser. I Math.,
 vol. 328,
 no. 12,
 pgs 1197-1202,
 1999.
\end{thebibliography}
\end{document}
